{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Deep Learning Workflows with Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Horovod](https://github.com/horovod/horovod) is a distributed deep learning training framework. It is available for TensorFlow, Keras, PyTorch, and Apache MXNet. In this lab you will learn about what Horovod is and how to use it, by distributing across multiple GPUs the training of an image classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Outline\n",
    "\n",
    "The progression of this lab is as follows:\n",
    "\n",
    "- A high level introduction to Horovod, including its ties to the parallel computing protocol MPI, and the additional details that must be taken into account when using a parallel computing framework like Horovod.\n",
    "- An overview and initial run of the existing code base that you will be refactoring with Horovod, which is a classification model using Keras and the Fashion-MNIST dataset, currently built to run on a single GPU.\n",
    "- A multi-step refactor of the existing code base so that it uses Horovod to run distributed across this environment's available GPUs, introducing Horovod concepts and techniques throughout.\n",
    "- A final run of the refactored and distributed code base, with discussion of its speed up.\n",
    "\n",
    "This lab draws heavily on content provided in the [Horovod tutorials](https://github.com/horovod/tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the time you complete this lab you will be able to:\n",
    "\n",
    "- Discuss what Horovod is, how it works, and why it is an effective tool for distributed training.\n",
    "- Use Horovod to refactor or build deep learning models that train distributed across multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Horovod\n",
    "\n",
    "[Horovod](https://github.com/horovod/horovod) is an open source tool originally [developed by Uber](https://eng.uber.com/horovod/) to support their need for faster deep learning model training across their many engineering teams. It is part of a growing ecosystem of approaches to distributed training, including for example [Distributed TensorFlow](https://www.tensorflow.org/deploy/distributed). Uber decided to develop a solution that utilized [MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) for distributed process communication, and the [NVIDIA Collective Communications Library (NCCL)](https://developer.nvidia.com/nccl) for its highly optimized implementation of reductions across distributed processes and nodes. The resulting Horovod package delivers on its promise to scale deep learning model training across multiple GPUs and multiple nodes, with only minor code modification and intuitive debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since its inception in 2017 Horovod has matured significantly, extending its support from just TensorFlow to Keras, PyTorch, and Apache MXNet. Horovod is extensively tested and has been used on some of the largest DL training runs done to date, for example, supporting **exascale** deep learning on the [Summit system, scaling to over **27,000 V100 GPUs**](https://arxiv.org/pdf/1810.01993.pdf):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![horovod scaling](./images/horovod_scaling.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import Horovod now so that we can query it later on. The convention is to import it as `hvd`. In this lab we will be using Keras, and Horovod has a backend for each implementation it supports, including Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import horovod.tensorflow.keras as hvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horovod's MPI Roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horovod's connection to MPI runs deep, and for programmers familiar with MPI programming, much of what you program to distribute model training with Horovod will feel very familiar. For those unfamiliar with MPI programming, a brief discussion of some of the conventions and considerations required when distributing processes with Horovod, or MPI, is worthwhile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horovod, as with MPI, strictly follows the [Single-Program Multiple-Data (SPMD) paradigm](https://en.wikipedia.org/wiki/SPMD) where we implement the instruction flow of multiple processes in the same file/program. Because multiple processes are executing code in parallel, we have to take care about [race conditions](https://en.wikipedia.org/wiki/Race_condition) and also the synchronization of participating processes.\n",
    "\n",
    "Horovod assigns a unique numerical ID or **rank** (an MPI concept) to each process executing the program. This rank can be accessed programmatically. As you will see below when writing Horovod code, by identifying a process's rank programmatically in the code we can take steps such as:\n",
    "\n",
    "- Pin that process to its own exclusive GPU.\n",
    "- Utilize a single rank for broadcasting values that need to be used uniformly by all ranks.\n",
    "- Utilize a single rank for collecting and/or reducing values produced by all ranks.\n",
    "- Utilize a single rank for logging or writing to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you work through this course, keep these concepts in mind and especially that Horovod will be sending your single program to be executed in parallel by multiple processes. Keeping this in mind will support your intuition and understanding about why we do what we do with Horovod, even though you will only be making edits to a single program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into modifications required to turn our serial training implementation into a parallel implementation, please make sure you can train the single GPU version of the model. We'll just run a few epochs with a relatively large batch size. This will take a few minutes, so go ahead and start the training, then read ahead to understand what model and dataset we are using. Take note of how long the training took when it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.7382 - accuracy: 0.1907\n",
      "Images/sec: 1117.51\n",
      "Cumulative training time after epoch 1: 53.72\n",
      "118/118 [==============================] - 54s 455ms/step - loss: 12.7402 - accuracy: 0.1907 - val_loss: 12.8110 - val_accuracy: 0.2054\n",
      "Epoch 2/5\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.9219 - accuracy: 0.1978\n",
      "Images/sec: 1614.36\n",
      "Cumulative training time after epoch 2: 90.89\n",
      "118/118 [==============================] - 37s 315ms/step - loss: 12.9236 - accuracy: 0.1977 - val_loss: 12.9319 - val_accuracy: 0.1987\n",
      "Epoch 3/5\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.9288 - accuracy: 0.1981\n",
      "Images/sec: 1603.92\n",
      "Cumulative training time after epoch 3: 128.3\n",
      "118/118 [==============================] - 37s 317ms/step - loss: 12.9296 - accuracy: 0.1981 - val_loss: 12.9314 - val_accuracy: 0.1990\n",
      "Epoch 4/5\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.9315 - accuracy: 0.1987\n",
      "Images/sec: 1601.78\n",
      "Cumulative training time after epoch 4: 165.76\n",
      "118/118 [==============================] - 37s 317ms/step - loss: 12.9283 - accuracy: 0.1989 - val_loss: 12.9271 - val_accuracy: 0.1993\n",
      "Epoch 5/5\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.9162 - accuracy: 0.1991\n",
      "Images/sec: 1599.71\n",
      "Cumulative training time after epoch 5: 203.28\n",
      "118/118 [==============================] - 38s 318ms/step - loss: 12.9201 - accuracy: 0.1988 - val_loss: 12.9289 - val_accuracy: 0.1991\n",
      "Cumulative training time: 203.28\n",
      "Test loss: 12.923389720916749\n",
      "Test accuracy: 0.1991\n"
     ]
    }
   ],
   "source": [
    "!python fashion_mnist.py --epochs 5 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Existing Model Files\n",
    "\n",
    "On the left hand side of this lab environment, you will see a file directory with this notebook, a Python file and a `solutions` directory.\n",
    "\n",
    "The file `fashion_mnist.py` contains the Keras model that does not have any Horovod code while `solutions/fashion_mnist_solution.py` has all the Horovod features added. In this tutorial, we will guide you to transform `fashion_mnist.py` into `solutions/fashion_mnist_solution.py` step-by-step. As you work through exercises to complete this task, you can, if needed compare your code with the `solutions/fashion_mnist_after_step_N.py` files that correspond to the step you are at.\n",
    "\n",
    "Take a couple of minutes to read through the `fashion_mnist.py`, familiarizing yourself with all that is happening in this original implementation. We assume your prerequisite understanding of deep learning is sufficient to understand what this initial code is doing; however, if anything is unfamiliar to you, consider taking the time to look up unfamiliar terms or methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fashion-MNIST Dataset\n",
    "\n",
    "The [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) is a response to the traditional MNIST dataset, which is often referred to as the \"hello world\" of machine learning. The original MNIST dataset consists of 60,000 pictures of handwritten digits, 0-9. One of the downsides of this dataset is its simplicity. Good performance of a model on the dataset does not indicate that the model will perform well on a more complicated set of images.\n",
    "\n",
    "The Fashion-MNIST dataset was created to be a moderately more complex image classification challenge. It follows the same format as the original MNIST set, with 10 categories and 60,000 training images, each 28x28 pixels (plus 10,000 testing images). We'll be training on this dataset for this lab. \n",
    "\n",
    "<img src=\"./images/Fashion MNIST.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Wide ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a Wide Residual Network to train on this dataset, which is a convolutional neural network proven to perform very well in image classification challenges. Feel free to take some time to learn more about [wide residual networks](https://arxiv.org/abs/1605.07146), the original [residual networks](https://arxiv.org/abs/1512.03385) they are based on, or about [convolutional neural networks](https://developer.nvidia.com/discover/convolutional-neural-network) in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/wideresnet.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the early days of CNNs, the community drove towards very deep models (many tens or hundreds of layers), but as computing power advanced and algorithms improved, in particular after the idea of the residual block was demonstrated, it became more desirable to swing back towards shallower networks with wider layers, which was the primary innovation of the WideResNet family of models. The WideResNet-16-10 we will use below can achieve with O(10 million) parameters accuracy that is competitive with much deeper networks with more parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start making modifications to the training script. Before we do, let's make a copy of it on disk -- that way, if you make a mistake and want to back up to the beginning, you have a reference copy to refer to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp fashion_mnist.py fashion_mnist_original.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click `fashion_mnist.py` in the left pane to open it in the editor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize Horovod and Select the GPU to Run On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally we need to start by importing Horovod. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Add `import horovod.keras as hvd` to the training script and initialize Horovod before the argument parsing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Horovod: initialize Horovod.\n",
    "hvd.init()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(look for the `TODO: Step 1` lines)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Horovod, which can run multiple processes across multiple GPUs, you typically use a single GPU per training process. Part of what makes Horovod simple to use is that it utilizes MPI, and as such, uses much of the MPI nomenclature. The concept of a **rank** in MPI is of a unique process ID. In this lab we will be using the term \"rank\" extensively. If you would like to know more about MPI concepts that are utilized heavily in Horovod, please refer to [the Horovod documentation](https://github.com/horovod/horovod/blob/master/docs/concepts.rst).\n",
    "\n",
    "Schematically, let's look at how MPI can run multiple GPU processes across multiple nodes. Note how each process, or rank, is pinned to a specific GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/16640218/53518255-7d5fc300-3a85-11e9-8bf3-5d0e8913c14f.png\" width=\"400\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this method we do not have to deal with placing specific data on specific GPUs. Instead, you just specify which GPU you would like to use in the beginning of your script. \n",
    "\n",
    "Before we get there, let's refresh ourselves on how to work with multiple GPUs on a node. On the NVIDIA platform, CUDA, if we have N GPUs they are uniquely numbered from 0 to N-1. In this lab we won't worry about how the numbering is selected or whether the order matters. Here is an example of working with multiple GPUs:\n",
    "\n",
    "```python\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list_physical_devices` returns an array of the GPUs (GPUS are \"devices\", in TensorFlow parlance) that this TensorFlow process is allowed to know about, from which we must select one to use. (CUDA enables you to restrict which GPUs a process can see, if you desire, but by default all GPUs on the server are visible to TensorFlow.) If you don't specify a GPU, then TensorFlow will use the first one in the list, which won't work in our data parallel use case where every process needs to use its own GPU.\n",
    "\n",
    "If you want to use multiple GPUs from this list, you can do so by manually controlling which device to use (see TensorFlow's [documentation](https://www.tensorflow.org/guide/gpu) for more information). Typically one would do so when manual control over the distribution of data is needed, and a common use case is model parallelism (which Horovod [does not natively support](https://github.com/horovod/horovod/issues/96)). In this lab we will only be using one GPU per rank.\n",
    "\n",
    "In this example we are using the `set_memory_growth` option. This tells TensorFlow to start with the minimum amount of GPU memory needed to start, and to allocate more on demand (like when the network is initialized). This is not strictly related to Horovod, but is a commonly used option when working with GPUs in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your understanding of how this works. First, let's identify how many GPUs are on our node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 11 19:06:07 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   35C    P0    36W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   35C    P0    36W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   39C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   37C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"!\" prefix means that we execute the above in the terminal; now let's do this in actual terminal. Open a new launcher (File > New Launcher in the menu bar), select the \"Terminal\" option, execute the `nvidia-smi` command there, and verify it provides the same output. Notice that there is a \"GPU-Util\" column, which measures the GPU's utilization. It tells you what fraction of the last second the GPU was in use. We can thus easily monitor GPU activity by regularly checking this output. One way to do that is using the Linux utility [watch](https://en.wikipedia.org/wiki/Watch_(Unix)): `watch -n 5 nvidia-smi` will set up a loop that refreshes the `nvidia-smi` output every 5 seconds. (You can also use the option `nvidia-smi --loop=5` to do this directly in the tool.) Make sure you run that in the separate terminal window, not here in the notebook, because the notebook can only run one process at a time. You can type Ctrl+C in the terminal to end the loop later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: set up `nvidia-smi` to regularly monitor the GPU activity in a terminal as above, and then here in the notebook start a training process. Then switch back to the terminal and watch the GPU activity. Can you verify that only one GPU is used? Does it match the GPU ID you asked for in the training script? Also, keep an eye out for other utilization metrics like power consumption and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/118 [============================>.] - ETA: 0s - loss: 11.3404 - accuracy: 0.2518\n",
      "Images/sec: 1083.22\n",
      "Cumulative training time after epoch 1: 55.4\n",
      "118/118 [==============================] - 55s 469ms/step - loss: 11.3389 - accuracy: 0.2521 - val_loss: 11.3396 - val_accuracy: 0.2865\n",
      "Cumulative training time: 55.4\n",
      "Test loss: 11.354074382781983\n",
      "Test accuracy: 0.2848\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 1 python fashion_mnist.py --epochs 1 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's modify the above code such that Horovod can automatically do the right thing for any number of training processes. Programmatically, we can arbitrarily select the GPU that corresponds to the Horovod rank and use that one. Since we might be using multiple nodes, and the Horovod rank is a unique identifier across all ranks in the training process, we want to identify our rank locally on the node, which is provided by the `local_rank` specifier. Then we provide the `local_rank` to the function `set_visible_devices` which controls the set of GPUs that are available to that rank:\n",
    "\n",
    "```python\n",
    "# Horovod: pin GPU to be used to process local rank (one GPU per process)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "if gpus:\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\n",
    "```\n",
    "\n",
    "Check out the documentation for both functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "A function that returns the Horovod rank of the calling process.\n",
       "\n",
       "Returns:\n",
       "  An integer scalar with the Horovod rank of the calling process.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.6/dist-packages/horovod/common/basics.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "A function that returns the local Horovod rank of the calling process, within the\n",
       "node that it is running on. For example, if there are seven processes running\n",
       "on a node, their local ranks will be zero through six, inclusive.\n",
       "\n",
       "Returns:\n",
       "  An integer scalar with the local Horovod rank of the calling process.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.6/dist-packages/horovod/common/basics.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.local_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: with this knowledge in hand, edit `fashion_mnist.py` to pin one GPU to each rank using its local rank ID, immediately after where you have already initialized Horovod.\n",
    "\n",
    "Again, look for `TODO: Step 1` lines in the code. If you get stuck, refer to `solutions/fashion_mnist_after_step_01.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Now let's test that you got this right too. Run the training script for just one epoch to make sure everything works. We'll get into the habit of launching with the Horovod job launcher, `horovodrun`, even though for a single process run this is unnecessary. Using `nvidia-smi` in the terminal, verify that only one training process is running, and note which GPU is being used. Is it the one you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/118 [============================>.] - ETA: 0s - loss: 6.7386 - accuracy: 0.3385\n",
      "Images/sec: 1081.44\n",
      "Cumulative training time after epoch 1: 55.49\n",
      "118/118 [==============================] - 55s 470ms/step - loss: 6.6971 - accuracy: 0.3398 - val_loss: 2.6832 - val_accuracy: 0.4578\n",
      "Cumulative training time: 55.49\n",
      "Test loss: 2.6879443407058714\n",
      "Test accuracy: 0.4592\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 1 python fashion_mnist.py --epochs 1 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`horovodrun` is a script that launches N copies of the training script, where N is the argument to `-np`. (For those familiar with MPI, it is a thin wrapper around `mpirun`, and in fact it is straightforward to distribute the training using `mpirun` with the right flags.) We'll be using it later to coordinate the training process. Because the processes are launched in the MPI environment, they can communicate between each other through a standardized API that Horovod handles for us, though we haven't instructed the training script to actually coordinate yet; at present we will just launch N independent copies of the same training script. We can try this out now by running as many processes (ranks) as there are GPUs. Watch the output and see if the training process appears to be coordinated -- does the training actually work? Do all of the processes run on the GPU you expect them to, and does that match the output of `nvidia-smi`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/118 [============================>.] - ETA: 0s - loss: 12.7471 - accuracy: 0.1890\n",
      "Images/sec: 1090.81\n",
      "Cumulative training time after epoch 1: 55.05\n",
      "118/118 [==============================] - 55s 466ms/step - loss: 7.7239 - accuracy: 0.2646 - val_loss: 2.7076 - val_accuracy: 0.4332\n",
      "Cumulative training time: 55.05\n",
      "\n",
      "Images/sec: 1088.01\n",
      "Cumulative training time after epoch 1: 55.18\n",
      "118/118 [==============================] - 55s 467ms/step - loss: 12.6447 - accuracy: 0.1954 - val_loss: 12.9347 - val_accuracy: 0.1998\n",
      "Cumulative training time: 55.18\n",
      "\n",
      "Images/sec: 1082.48\n",
      "Cumulative training time after epoch 1: 55.47\n",
      "118/118 [==============================] - 55s 470ms/step - loss: 4.7881 - accuracy: 0.3874 - val_loss: 1.2071 - val_accuracy: 0.6032\n",
      "Cumulative training time: 55.47\n",
      "\n",
      "Images/sec: 1080.73\n",
      "Cumulative training time after epoch 1: 55.58\n",
      "118/118 [==============================] - 56s 470ms/step - loss: 12.7503 - accuracy: 0.1890 - val_loss: 12.9868 - val_accuracy: 0.1863\n",
      "Cumulative training time: 55.58\n",
      "Test loss: 2.70180059671402\n",
      "Test accuracy: 0.4339\n",
      "Test loss: 12.90794243812561\n",
      "Test accuracy: 0.2\n",
      "Test loss: 1.208978646993637\n",
      "Test accuracy: 0.6021\n",
      "Test loss: 12.972663974761963\n",
      "Test accuracy: 0.1871\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 1 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Print Verbose Logs Only on the First Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably noticed that all N TensorFlow processes printed their progress to stdout (standard output). This results in confusing output -- we only want to see the state of the output once at any given time. To accomplish this, we can arbitrarily select a single rank to display the training progress. By convention, we typically call rank 0 the \"root\" rank and use it for logistical work such as I/O when only one rank is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Edit `fashion_mnist.py` so that you only set `verbose = 1` if it is the first worker (with rank equal to 0) executing the code.\n",
    "\n",
    "Look for `TODO: Step 2` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_02.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the training session to make sure that you now see the expected output. We'll run for 3 epochs this time for comparison to the next exercise. While it's running, you can start working on Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.7565 - accuracy: 0.1917\n",
      "Images/sec: 1081.7\n",
      "Cumulative training time after epoch 1: 55.51\n",
      "118/118 [==============================] - 55s 470ms/step - loss: 12.7606 - accuracy: 0.1916 - val_loss: 12.9406 - val_accuracy: 0.1983\n",
      "Epoch 2/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.9243 - accuracy: 0.1982\n",
      "Images/sec: 1608.47\n",
      "Cumulative training time after epoch 2: 92.82\n",
      "118/118 [==============================] - 37s 316ms/step - loss: 12.9234 - accuracy: 0.1983 - val_loss: 12.9170 - val_accuracy: 0.1986\n",
      "Epoch 3/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 12.9157 - accuracy: 0.1991\n",
      "Images/sec: 1609.67\n",
      "Cumulative training time after epoch 3: 130.1\n",
      "118/118 [==============================] - 37s 316ms/step - loss: 12.9206 - accuracy: 0.1988 - val_loss: 12.9291 - val_accuracy: 0.1991\n",
      "Cumulative training time: 130.1\n",
      "Test loss: 12.929070806503296\n",
      "Test accuracy: 0.1991\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add Distributed Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous two sections we ran with multiple processes, but each process was running completely independently -- this is not data parallel training, it is just multiple processes running serial training at the same time. The key step to make the training data parallel is to average out gradients across all workers, so that all workers are updating with the same gradients and thus moving in the same direction. Horovod implements an operation that averages gradients across workers. Deploying this in your code is very straightforward and just requires wrapping an existing optimizer (`keras.optimizers.Optimizer`) with a Horovod distributed optimizer (`horovod.keras.DistributedOptimizer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice_dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevice_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'horovod.tensorflow.compression.NoneCompressor'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msparse_as_dense\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "An optimizer that wraps another keras.optimizers.Optimizer, using an allreduce to\n",
       "average gradient values before applying gradients to model weights.\n",
       "\n",
       "Args:\n",
       "    optimizer: Optimizer to use for computing gradients and applying updates.\n",
       "    name: Optional name prefix for the operations created when applying\n",
       "          gradients. Defaults to \"Distributed\" followed by the provided\n",
       "          optimizer type.\n",
       "    device_dense: Device to be used for dense tensors. Uses GPU by default\n",
       "                  if Horovod was build with HOROVOD_GPU_ALLREDUCE.\n",
       "    device_sparse: Device to be used for sparse tensors. Uses GPU by default\n",
       "                   if Horovod was build with HOROVOD_GPU_ALLGATHER.\n",
       "    compression: Compression algorithm used to reduce the amount of data\n",
       "                 sent and received by each worker node.  Defaults to not\n",
       "                 using compression.\n",
       "    sparse_as_dense: Treat all sparse gradients as dense tensors.  This can\n",
       "                     help improve performance and memory utilization if\n",
       "                     the original sparse gradient has high density.\n",
       "                     Defaults to false.    \n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/keras/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.DistributedOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: wrap the optimizer (`opt` in `fashion_mnist.py`) with a Horovod distributed optimizer.\n",
    "\n",
    "Look for `TODO: Step 3` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_03.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the training now and see if you get a reasonable answer. Is the accuracy any better? Note that we are only training for a few epochs, and the results will depend on the initial random weights, so do not draw any strong conclusions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 1.9639 - accuracy: 0.5429\n",
      "Images/sec: 1032.74\n",
      "Cumulative training time after epoch 1: 58.13\n",
      "118/118 [==============================] - 58s 492ms/step - loss: 1.9539 - accuracy: 0.5445 - val_loss: 0.9019 - val_accuracy: 0.6973\n",
      "Epoch 2/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.7099 - accuracy: 0.7560\n",
      "Images/sec: 1573.41\n",
      "Cumulative training time after epoch 2: 96.27\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.7096 - accuracy: 0.7562 - val_loss: 0.6435 - val_accuracy: 0.7797\n",
      "Epoch 3/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.5884 - accuracy: 0.7961\n",
      "Images/sec: 1556.52\n",
      "Cumulative training time after epoch 3: 134.83\n",
      "118/118 [==============================] - 39s 327ms/step - loss: 0.5883 - accuracy: 0.7961 - val_loss: 0.7016 - val_accuracy: 0.7670\n",
      "Cumulative training time: 134.83\n",
      "Test loss: 0.7015880823135376\n",
      "Test accuracy: 0.767\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initialize Random Weights on Only One Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data parallel stochastic gradient descent, at least in its traditionally defined sequential algorithm, requires weights to be synchronized between all processors. We already know that this is accomplished for backpropagation by averaging out the gradients among all processors prior to the weight updates. Then the only other required step is for the weights to be synchronized initially. Assuming we start from the beginning of the training (we'll handle checkpoint/restart later), this means that every processor needs to have the same random weights.\n",
    "\n",
    "In a previous section, we mentioned that the first worker would broadcast parameters to the rest of the workers.  We will use `horovod.keras.callbacks.BroadcastGlobalVariablesCallback` to make this happen. Execute the following cell to get more information about the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBroadcastGlobalVariablesCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Keras Callback that will broadcast all global variables from root rank\n",
       "to all other processes during initialization.\n",
       "\n",
       "This is necessary to ensure consistent initialization of all workers when\n",
       "training is started with random weights or restored from a checkpoint.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a new BroadcastGlobalVariablesCallback that will broadcast all\n",
       "global variables from root rank to all other processes during initialization.\n",
       "\n",
       "Args:\n",
       "    root_rank: Rank that will send data, other ranks will receive data.\n",
       "    device: Device to be used for broadcasting. Uses GPU by default\n",
       "            if Horovod was build with HOROVOD_GPU_BROADCAST.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/keras/callbacks.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.callbacks.BroadcastGlobalVariablesCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: append this callback to our list of callbacks. Note the argument required for this callback, the rank of the root worker. Note that introducing this callback causes a TensorFlow warning, which you can disregard.\n",
    "\n",
    "Look for `TODO: Step 4` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_04.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run the training session for just a few epochs to make sure things work, and notice if it affected the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  1/118 [..............................] - ETA: 34:29 - loss: 4.7212 - accuracy: 0.0918WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.613982). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.613957). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.613917). Check your callbacks.\n",
      "  2/118 [..............................] - ETA: 17:22 - loss: 4.4915 - accuracy: 0.1162WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.613979). Check your callbacks.\n",
      "117/118 [============================>.] - ETA: 0s - loss: 2.6502 - accuracy: 0.5209\n",
      "Images/sec: 1004.99\n",
      "Cumulative training time after epoch 1: 59.74\n",
      "118/118 [==============================] - 60s 506ms/step - loss: 2.6350 - accuracy: 0.5224 - val_loss: 0.9490 - val_accuracy: 0.6678\n",
      "Epoch 2/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.6373 - accuracy: 0.7767\n",
      "Images/sec: 1562.34\n",
      "Cumulative training time after epoch 2: 98.15\n",
      "118/118 [==============================] - 38s 325ms/step - loss: 0.6367 - accuracy: 0.7768 - val_loss: 0.5645 - val_accuracy: 0.8010\n",
      "Epoch 3/3\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.8304\n",
      "Images/sec: 1573.49\n",
      "Cumulative training time after epoch 3: 136.29\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.4923 - accuracy: 0.8304 - val_loss: 0.6424 - val_accuracy: 0.7811\n",
      "Cumulative training time: 136.29\n",
      "Test loss: 0.6424222737550735\n",
      "Test accuracy: 0.7811\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modify Training Loop to Execute Fewer Steps Per Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, we are running the same number of steps per epoch for the serial training implementation. But since we have increased the number of workers by a factor of N, that means we're doing N times more work (when we sum the amount of work done over all processes). Our target was to get the *same* answer in less time (that is, to speed up the training), so we want to keep the total amount of work done the same (that is, to process the same number of examples in the dataset). This means we need to do a factor of N *fewer* steps per epoch, so the number of steps goes to `steps_per_epoch / number_of_workers`.\n",
    "\n",
    "We will also speed up validation by validating `3 * num_test_iterations / number_of_workers` steps on each worker. While we could just do `num_test_iterations / number_of_workers` on each worker to get a linear speedup in the validation, the multiplier **3** provides over-sampling of the validation data and helps to increase the probability that every validation example will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "A function that returns the number of Horovod processes.\n",
       "\n",
       "Returns:\n",
       "  An integer scalar containing the number of Horovod processes.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.6/dist-packages/horovod/common/basics.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: modify the `steps_per_epoch` and `validation_steps` arguments for `model.fit_generator` to follow the plan just outlined. This environment uses Python 3, and each of these arguments expect integers, so take care to round any potential floating point values down to the nearest integer.\n",
    "\n",
    "Look for `TODO: Step 5` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_05.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/29 [>.............................] - ETA: 8:03 - loss: 5.3456 - accuracy: 0.1172WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.789326). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.789514). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.789767). Check your callbacks.\n",
      " 2/29 [=>............................] - ETA: 3:56 - loss: 4.8497 - accuracy: 0.1289WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.789318). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 8.5687 - accuracy: 0.2096\n",
      "Images/sec: 2067.52\n",
      "Cumulative training time after epoch 1: 29.07\n",
      "29/29 [==============================] - 29s 1s/step - loss: 8.4759 - accuracy: 0.2105 - val_loss: 14.3495 - val_accuracy: 0.1009\n",
      "Epoch 2/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9751 - accuracy: 0.4358\n",
      "Images/sec: 5680.95\n",
      "Cumulative training time after epoch 2: 39.63\n",
      "29/29 [==============================] - 11s 364ms/step - loss: 1.9482 - accuracy: 0.4405 - val_loss: 3.7182 - val_accuracy: 0.2863\n",
      "Epoch 3/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0386 - accuracy: 0.6371\n",
      "Images/sec: 5631.59\n",
      "Cumulative training time after epoch 3: 50.29\n",
      "29/29 [==============================] - 11s 367ms/step - loss: 1.0335 - accuracy: 0.6396 - val_loss: 0.9740 - val_accuracy: 0.6624\n",
      "Cumulative training time: 50.29\n",
      "Test loss: 0.974322971701622\n",
      "Test accuracy: 0.6612\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Average Validation Results Among Workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not validating the full dataset on each worker anymore, each worker will have different validation results. To improve validation metric quality and reduce variance, we will average validation results among all workers.\n",
    "\n",
    "To do so, we can use `horovod.keras.callbacks.MetricAverageCallback`. Execute the following cell to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetricAverageCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Keras Callback that will average metrics across all processes at the\n",
       "end of the epoch. Useful in conjuction with ReduceLROnPlateau,\n",
       "TensorBoard and other metrics-based callbacks.\n",
       "\n",
       "Note: This callback must be added to the callback list before the\n",
       "ReduceLROnPlateau, TensorBoard or other metrics-based callbacks.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a new MetricAverageCallback that will average metrics\n",
       "across all processes at the end of the epoch.\n",
       "\n",
       "Args:\n",
       "    device: Device to be used for allreduce. Uses GPU by default\n",
       "            if Horovod was build with HOROVOD_GPU_ALLREDUCE.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/keras/callbacks.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.callbacks.MetricAverageCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: average the metrics among workers at the end of every epoch by injecting `MetricAverageCallback` after `BroadcastGlobalVariablesCallback`. Please note that this callback must be in the list before other metrics-based callbacks, `ReduceLROnPlateau`, `TensorBoard`, etc.\n",
    "\n",
    "Look for `TODO: Step 6` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_06.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/29 [>.............................] - ETA: 7:49 - loss: 4.0224 - accuracy: 0.0801WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.644744). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.644746). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.644740). Check your callbacks.\n",
      " 2/29 [=>............................] - ETA: 3:50 - loss: 4.1500 - accuracy: 0.1172WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.644504). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 9.9574 - accuracy: 0.1417 \n",
      "Images/sec: 2109.68\n",
      "Cumulative training time after epoch 1: 28.48\n",
      "29/29 [==============================] - 28s 983ms/step - loss: 9.8359 - accuracy: 0.1472 - val_loss: 13.0356 - val_accuracy: 0.1134\n",
      "Epoch 2/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.4507 - accuracy: 0.2996\n",
      "Images/sec: 5885.99\n",
      "Cumulative training time after epoch 2: 38.74\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 3.3866 - accuracy: 0.3006 - val_loss: 3.4673 - val_accuracy: 0.3138\n",
      "Epoch 3/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3321 - accuracy: 0.5352\n",
      "Images/sec: 5713.81\n",
      "Cumulative training time after epoch 3: 49.31\n",
      "29/29 [==============================] - 11s 363ms/step - loss: 1.3237 - accuracy: 0.5301 - val_loss: 1.2360 - val_accuracy: 0.5812\n",
      "Cumulative training time: 49.35\n",
      "Test loss: 1.2392199099063874\n",
      "Test accuracy: 0.5809\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Do Checkpointing Logic Only Using the Root Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpointing is a common activity in production DL training (for simplicity we are not relying on it in this lab, however). This is extremely important for \"defensive I/O\" purposes (so that if a process or node fails, we don't lose all our work), and is also useful for being able to chart the progress of our training run. Let's think about how that works in the multi-process context.\n",
    "\n",
    "The most important issue is that there can be a race condition while writing the checkpoint to a file. If every rank finishes the epoch at the same time, they might be writing to the same filename, and this could result in corrupted data. But more to the point, we don't even need to do this: by construction in synchronous data parallel SGD, every rank has the same copy of the weights at all times, so only one worker needs to write the checkpoint. As usual, our convention will be that the root worker (rank 0) handles this.\n",
    "\n",
    "For the same reason, if we are restarting from a checkpoint later on, we don't need every rank to read in the checkpoint -- only one rank needs to do so, and then it can broadcast the data to all the other workers. (In that case, all the workers do still need to instantiate the same model as the one in the checkpoint.) We also often don't want every rank to read in the checkpoint -- at large enough scale, having thousands of processes all read from the same file on disk can be inefficient. You might also be in a situation where only one server node has the data available, so the broadcast is necessary in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already encountered broadcasting in the form of a callback in Step 4. But with Horovod we can take direct control and broadcast (that is, send some data from one processor to every other processor) a specific scalar or tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Perform a broadcast on a tensor-compatible value.\n",
       "\n",
       "Arguments:\n",
       "    value: A tensor-compatible value to reduce.\n",
       "           The shape of the input must be identical across all ranks.\n",
       "    root_rank: Rank of the process from which global variables will be\n",
       "               broadcasted to all other processes.\n",
       "    name: Optional name for the constants created by this operation.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/keras/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script has a function `restart_epoch()` which looks for the latest checkpoint we have created and returns the epoch number corresponding to that checkpoint. By default, every rank is resuming from epoch 0 (look for the `resume_from_epoch` variable), which means start from the beginning without loading a checkpoint. We can run the `restart_epoch()` function to actively look for checkpoints, but we only need to do this on one rank, and then we can have that same rank broadcast that epoch number to all other ranks, and also read in the checkpoint and broadcast the checkpointed weights (this is already handled by the `BroadcastGlobalVariablesCallback` we implemented in Step 4).\n",
    "\n",
    "**Exercise**: edit `fashion_mnist.py` so that after\n",
    "\n",
    "```python\n",
    "resume_from_epoch = 0\n",
    "```\n",
    "\n",
    "you:\n",
    "\n",
    "(1) update the `resume_from_epoch` variable on rank 0 (the root process) using the `restart_epoch()` function;\n",
    "\n",
    "(2) broadcast the value of this data to all other processes; and,\n",
    "\n",
    "(3) uncomment the checkpointing callbacks, and make sure they're only appended on rank 0.\n",
    "\n",
    "Use the docstring printed above to assist your work in getting the syntax right.\n",
    "\n",
    "Look for `TODO: Step 7` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_07.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/29 [>.............................] - ETA: 7:49 - loss: 4.3684 - accuracy: 0.1270WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.615154). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.615176). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.615102). Check your callbacks.\n",
      "2021-11-11 19:31:27.974364: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.636009). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 9.6678 - accuracy: 0.1771\n",
      "Images/sec: 2108.65\n",
      "Cumulative training time after epoch 1: 28.52\n",
      "29/29 [==============================] - 29s 993ms/step - loss: 9.6386 - accuracy: 0.1745 - val_loss: 10.1377 - val_accuracy: 0.2265\n",
      "Epoch 2/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 6.5048 - accuracy: 0.2357\n",
      "Images/sec: 5708.0\n",
      "Cumulative training time after epoch 2: 39.38\n",
      "29/29 [==============================] - 11s 376ms/step - loss: 6.4554 - accuracy: 0.2362 - val_loss: 11.2276 - val_accuracy: 0.1716\n",
      "Epoch 3/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.6276 - accuracy: 0.3891\n",
      "Images/sec: 5924.9\n",
      "Cumulative training time after epoch 3: 49.89\n",
      "29/29 [==============================] - 10s 359ms/step - loss: 2.5997 - accuracy: 0.3928 - val_loss: 2.9725 - val_accuracy: 0.3530\n",
      "Cumulative training time: 50.18\n",
      "Test loss: 2.9833685874938967\n",
      "Test accuracy: 0.3482\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512 --use-checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test to make sure we did the checkpointing correctly by running for another 2 epochs, making sure that we start at epoch 4 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      " 1/29 [>.............................] - ETA: 3:05 - loss: 1.8052 - accuracy: 0.4512WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.664047). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.673051). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.725105). Check your callbacks.\n",
      "2021-11-11 19:32:23.424203: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.580734). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.5859 - accuracy: 0.5075\n",
      "Images/sec: 1802.19\n",
      "Cumulative training time after epoch 4: 33.3\n",
      "29/29 [==============================] - 34s 1s/step - loss: 1.5840 - accuracy: 0.4991 - val_loss: 2.5247 - val_accuracy: 0.4956\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.2064 - accuracy: 0.5874\n",
      "Images/sec: 2168.59\n",
      "Cumulative training time after epoch 5: 62.06\n",
      "29/29 [==============================] - 28s 965ms/step - loss: 1.2123 - accuracy: 0.5688 - val_loss: 1.1892 - val_accuracy: 0.5921\n",
      "Cumulative training time: 62.39\n",
      "Test loss: 1.1462138891220093\n",
      "Test accuracy: 0.5784\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 5 --batch-size 512 --use-checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you make any mistakes, you can simply delete the logs directory and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make necessary algorithmic adjustments\n",
    "\n",
    "So far we've just gone through the mechanics of how to do distributed training. But we haven't discussed what algorithm adjustments need to be made when you are training at larger scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Increase the learning rate\n",
    "\n",
    "Given a fixed batch size per GPU, the effective batch size for training increases when you use more GPUs, since we average out the gradients among all processors. [Standard practice](https://arxiv.org/abs/1404.5997) is to scale the learning rate by the same factor that you have scaled the batch size -- that is, by the number of workers present. This can be done so that the training script does not change for single-process runs, since in that case you just multiply by 1.\n",
    "\n",
    "The reason we do this is that the error of a mean of *n* samples (random variables) with finite variance *sigma* is approximately sigma/sqrt(n) when *n* is large (see the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)). Hence, learning rates should be scaled at least with sqrt(k) when using *k* times bigger batch sizes in order to preserve the variance of the batch-averaged gradient. In practice we use linear scaling, often out of convenience, although in different circumstances one or the other may be superior in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Scale the learning rate by the number of workers, and look at the effect on the training accuracy, if any.\n",
    "\n",
    "Look for `TODO: Step 8` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_08.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/29 [>.............................] - ETA: 8:29 - loss: 4.2376 - accuracy: 0.0996WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.715118). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.715089). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.715145). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.715100). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11.3651 - accuracy: 0.1756\n",
      "Images/sec: 2037.53\n",
      "Cumulative training time after epoch 1: 29.48\n",
      "29/29 [==============================] - 30s 1s/step - loss: 11.3675 - accuracy: 0.1743 - val_loss: 11.5987 - val_accuracy: 0.2198\n",
      "Epoch 2/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 7.7994 - accuracy: 0.1947\n",
      "Images/sec: 5910.99\n",
      "Cumulative training time after epoch 2: 39.7\n",
      "29/29 [==============================] - 10s 351ms/step - loss: 7.6673 - accuracy: 0.2035 - val_loss: 7.0945 - val_accuracy: 0.1971\n",
      "Epoch 3/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0920 - accuracy: 0.3710\n",
      "Images/sec: 5537.51\n",
      "Cumulative training time after epoch 3: 50.57\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 2.0653 - accuracy: 0.3803 - val_loss: 1.5576 - val_accuracy: 0.4399\n",
      "Cumulative training time: 50.73\n",
      "Test loss: 1.5546909868717194\n",
      "Test accuracy: 0.4402\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Add learning rate warmup\n",
    "\n",
    "As it stands in `fashion_mnist.py`, we are using `keras.callbacks.LearningRateScheduler` along with the user-defined `lr_schedule` function, to reduce the learning rate (LR) by a factor of 10 on the 15th, 25th and 35th epochs:\n",
    "\n",
    "```python\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return args.base_lr\n",
    "    if epoch < 25:\n",
    "        return 1e-1 * args.base_lr\n",
    "    if epoch < 35:\n",
    "        return 1e-2 * args.base_lr\n",
    "    return 1e-3 * args.base_lr\n",
    "\n",
    "callbacks.append(keras.callbacks.LearningRateScheduler(lr_schedule))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models are sensitive to using a large learning rate immediately after initialization and can benefit from learning rate warmup. We saw earlier that we typically scale the learning rate linear with batch sizes. But if the batch size gets large enough, then the learning rate will be very high, and the network tends to diverge, especially in the very first few iterations. We counteract this by gently ramping the learning rate to the target learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, the idea is to start training with a lower learning rate and [gradually raise it to a target learning rate](https://arxiv.org/abs/1706.02677) over a few epochs. Horovod has the convenient `horovod.keras.callbacks.LearningRateWarmupCallback` for the Keras API that implements that logic. By default it will, over the first 5 epochs, gradually increase the learning rate from *initial learning rate* / *number of workers* up to *initial learning rate*. Execute the following cell to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateWarmupCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarmup_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmomentum_correction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Implements gradual learning rate warmup:\n",
       "\n",
       "    `lr = initial_lr / hvd.size()` ---> `lr = initial_lr`\n",
       "\n",
       "`initial_lr` is the learning rate of the model optimizer at the start of the training.\n",
       "\n",
       "This technique was described in the paper \"Accurate, Large Minibatch SGD: Training\n",
       "ImageNet in 1 Hour\". See https://arxiv.org/pdf/1706.02677.pdf for details.\n",
       "\n",
       "Math recap:\n",
       "\n",
       ".. math::\n",
       "\n",
       "    epoch &= full\\_epochs + \\frac{batch}{steps\\_per\\_epoch}\n",
       "\n",
       "    lr'(epoch) &= \\frac{lr}{size} * (\\frac{size - 1}{warmup} * epoch + 1)\n",
       "\n",
       "    lr'(epoch = 0) &= \\frac{lr}{size}\n",
       "\n",
       "    lr'(epoch = warmup) &= lr\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a new LearningRateWarmupCallback that will gradually warm up the learning rate.\n",
       "\n",
       "Args:\n",
       "    warmup_epochs: The number of epochs of the warmup phase. Defaults to 5.\n",
       "    momentum_correction: Apply momentum correction to optimizers that have momentum.\n",
       "                         Defaults to True.\n",
       "    steps_per_epoch: The callback will attempt to autodetect number of batches per\n",
       "                     epoch with Keras >= 2.0.0. Provide this value if you have an older\n",
       "                     version of Keras.\n",
       "    verbose: verbosity mode, 0 or 1.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/keras/callbacks.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.callbacks.LearningRateWarmupCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also swap out `keras.callbacks.LearningRateScheduler` for `horovod.keras.callbacks.LearningRateScheduleCallback`. Execute the following cell to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mhvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduleCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmultiplier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mend_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstaircase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmomentum_correction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "LearningRateScheduleCallback sets learning rate between epochs `start_epoch` and\n",
       "`end_epoch` to be `initial_lr * multiplier`.  `multiplier` can be a constant or\n",
       "a function `f(epoch) = lr'`.\n",
       "\n",
       "If `multiplier` is a function and `staircase=True`, learning rate adjustment will\n",
       "happen at the beginning of each epoch and the epoch passed to the `multiplier`\n",
       "function will be an integer.\n",
       "\n",
       "If `multiplier` is a function and `staircase=False`, learning rate adjustment will\n",
       "happen at the beginning of each batch and the epoch passed to the `multiplier`\n",
       "function will be a floating number: `epoch' = epoch + batch / steps_per_epoch`.\n",
       "This functionality is useful for smooth learning rate adjustment schedulers, such\n",
       "as `LearningRateWarmupCallback`.\n",
       "\n",
       "`initial_lr` is the learning rate of the model optimizer at the start of the training.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Construct a new LearningRateScheduleCallback.\n",
       "\n",
       "Args:\n",
       "    multiplier: A constant multiplier or a function `f(epoch) = lr'`\n",
       "    start_epoch: The first epoch this adjustment will be applied to. Defaults to 0.\n",
       "    end_epoch: The epoch this adjustment will stop applying (exclusive end).\n",
       "               Defaults to None.\n",
       "    staircase: Whether to adjust learning rate at the start of epoch (`staircase=True`)\n",
       "               or at the start of every batch (`staircase=False`).\n",
       "    momentum_correction: Apply momentum correction to optimizers that have momentum.\n",
       "                         Defaults to True.\n",
       "    steps_per_epoch: The callback will attempt to autodetect number of batches per\n",
       "                     epoch with Keras >= 2.0.0. Provide this value if you have an older\n",
       "                     version of Keras.\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/keras/callbacks.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?hvd.callbacks.LearningRateScheduleCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still pass `lr_schedule` as the `multiplier` argument to `horovod.keras.callbacks.LearningRateScheduleCallback`. However this callback is invoked every epoch and we do not want it to conflict with `horovod.keras.callbacks.LearningRateWarmupCallback`. So we will also need to set its `start_epoch` argument such that it is only invoked after the warmup period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Add learning rate warmup to our training script.\n",
    "\n",
    "First, register a new `warmup-epochs` argument using the following code:\n",
    "```python\n",
    "parser.add_argument('--warmup-epochs', type=float, default=5,\n",
    "                    help='number of warmup epochs')\n",
    "```\n",
    "\n",
    "Second, using `args.warmup_epochs` as the `warmup_epochs` argument, implement a learning rate warmup. Please also set the `verbose` argument to `verbose`.\n",
    "\n",
    "Third, replace `keras.callbacks.LearningRateScheduler` with `horovod.keras.callbacks.LearningRateScheduleCallback`, using `lr_schedule` as the `multiplier` argument, and taking care to not start the callback until after the warmup epochs have completed.\n",
    "\n",
    "Look for `TODO: Step 9` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_09.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/29 [>.............................] - ETA: 11:34 - loss: 6.1509 - accuracy: 0.0957WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.854273). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.854228). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.854295). Check your callbacks.\n",
      " 2/29 [=>............................] - ETA: 5:39 - loss: 5.5057 - accuracy: 0.0928 WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.854289). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 1s - loss: 1.9636 - accuracy: 0.4513\n",
      "Images/sec: 1658.04\n",
      "Cumulative training time after epoch 1: 36.19\n",
      "29/29 [==============================] - 36s 1s/step - loss: 1.9300 - accuracy: 0.4574 - val_loss: 1.7922 - val_accuracy: 0.3289\n",
      "Epoch 2/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7798 - accuracy: 0.7382\n",
      "Images/sec: 5484.47\n",
      "Cumulative training time after epoch 2: 47.19\n",
      "29/29 [==============================] - 11s 381ms/step - loss: 0.7777 - accuracy: 0.7377 - val_loss: 0.8668 - val_accuracy: 0.6963\n",
      "Epoch 3/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6475 - accuracy: 0.7777\n",
      "Images/sec: 5270.21\n",
      "Cumulative training time after epoch 3: 58.67\n",
      "29/29 [==============================] - 11s 393ms/step - loss: 0.6460 - accuracy: 0.7779 - val_loss: 0.6995 - val_accuracy: 0.7473\n",
      "Cumulative training time: 58.7\n",
      "Test loss: 0.6973326444625855\n",
      "Test accuracy: 0.7489\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Change the optimizer\n",
    "\n",
    "You will likely find that as you scale to multiple GPUs and the resulting overall batch size increases, accuracy of the network will suffer. A series of optimizers have been created to address this problem, and allow for scaling to very large batch sizes and learning rates. In this exercise we'll be using the [NovoGrad optimizer](https://arxiv.org/abs/1905.11286). NovoGrad has the standard form of an update to the weights,\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\large\n",
    "  \\Delta \\mathbf{w} = -\\lambda\\, \\mathbf{m}\n",
    "\\end{equation*}\n",
    "\n",
    "but the $\\mathbf{m}$ term appropriately normalizes the gradients to avoid the [vanishing gradient (or exploding gradient) problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), using a gradient-averaging scheme similar to how SGD uses momentum to do that normalization. NovoGrad ensures that the learning rate is scaled appropriately on each layer, which empirically is [important in the large batch regime](https://arxiv.org/abs/1708.03888). If you are interested in continuing this exploration after this course, the [LAMB optimizer](https://arxiv.org/abs/1904.00962) is another extremely promising recent method worth exploring, which is very similar to NovoGrad in that it combines both [Adam](https://arxiv.org/abs/1412.6980), a popular variant of SGD, and layer-wise learning rates.\n",
    "\n",
    "**Exercise**: Use the NovoGrad optimizer.\n",
    "\n",
    "Replace the SGD optimizer with the NovoGrad optimizer and pass in the learning rate multiplied by the number of ranks. \n",
    "\n",
    "Look for `TODO: Step 10` in `fashion_mnist.py`. If you get stuck, refer to `solutions/fashion_mnist_after_step_10.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 1/29 [>.............................] - ETA: 11:39 - loss: 3.6120 - accuracy: 0.1133WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.907524). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.907563). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.907575). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.907523). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 1s - loss: 1.5636 - accuracy: 0.4884\n",
      "Images/sec: 1647.81\n",
      "Cumulative training time after epoch 1: 36.41\n",
      "29/29 [==============================] - 36s 1s/step - loss: 1.5414 - accuracy: 0.4972 - val_loss: 1.2357 - val_accuracy: 0.5845\n",
      "Epoch 2/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7574 - accuracy: 0.7405\n",
      "Images/sec: 5338.6\n",
      "Cumulative training time after epoch 2: 47.7\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.7548 - accuracy: 0.7416 - val_loss: 0.7407 - val_accuracy: 0.7438\n",
      "Epoch 3/3\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6069 - accuracy: 0.7913\n",
      "Images/sec: 5605.01\n",
      "Cumulative training time after epoch 3: 58.58\n",
      "29/29 [==============================] - 11s 371ms/step - loss: 0.6062 - accuracy: 0.7943 - val_loss: 0.7894 - val_accuracy: 0.7374\n",
      "Cumulative training time: 58.63\n",
      "Test loss: 0.7952311754226684\n",
      "Test accuracy: 0.7349\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 3 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your work\n",
    "\n",
    "Congratulations!  If you made it this far, your `fashion_mnist.py` should now be fully distributed. To verify, compare `fashion_mnist.py` to `fashion_mnist_solution.py`, and make any changes you might have missed.\n",
    "\n",
    "If you haven't already, run a 1 GPU training session and compare it to a training session using all of the GPUs you have. Train for a decent number of epochs and compare both accuracy and time to solution. Ideally you'd get through the epochs faster by a factor of the number of GPUs you have, but for a model this small you probably won't get perfectly linear scaling like that. Still, you probably got a nice speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/118 [..............................] - ETA: 42:56 - loss: 4.4226 - accuracy: 0.1191WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.741361). Check your callbacks.\n",
      "117/118 [============================>.] - ETA: 0s - loss: 1.0277 - accuracy: 0.6611\n",
      "Images/sec: 883.84\n",
      "Cumulative training time after epoch 1: 67.89\n",
      "118/118 [==============================] - 68s 575ms/step - loss: 1.0248 - accuracy: 0.6620 - val_loss: 0.6821 - val_accuracy: 0.7748\n",
      "Epoch 2/20\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.6002 - accuracy: 0.7950\n",
      "Images/sec: 1393.82\n",
      "Cumulative training time after epoch 2: 110.96\n",
      "118/118 [==============================] - 43s 365ms/step - loss: 0.5992 - accuracy: 0.7955 - val_loss: 0.5432 - val_accuracy: 0.8189\n",
      "Epoch 3/20\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.5100 - accuracy: 0.8261\n",
      "Images/sec: 1403.09\n",
      "Cumulative training time after epoch 3: 153.75\n",
      "118/118 [==============================] - 43s 363ms/step - loss: 0.5104 - accuracy: 0.8259 - val_loss: 0.5021 - val_accuracy: 0.8308\n",
      "Epoch 4/20\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.8438\n",
      "Images/sec: 1396.81\n",
      "Cumulative training time after epoch 4: 196.73\n",
      "118/118 [==============================] - 43s 364ms/step - loss: 0.4534 - accuracy: 0.8440 - val_loss: 0.5144 - val_accuracy: 0.8291\n",
      "Epoch 5/20\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.4245 - accuracy: 0.8559\n",
      "Epoch 5: finished gradual learning rate warmup to 0.01.\n",
      "\n",
      "Images/sec: 1398.63\n",
      "Cumulative training time after epoch 5: 239.66\n",
      "118/118 [==============================] - 43s 364ms/step - loss: 0.4243 - accuracy: 0.8559 - val_loss: 0.5703 - val_accuracy: 0.8085\n",
      "Epoch 6/20\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.4780 - accuracy: 0.8345\n",
      "Images/sec: 1406.01\n",
      "Cumulative training time after epoch 6: 282.36\n",
      "118/118 [==============================] - 43s 362ms/step - loss: 0.4774 - accuracy: 0.8349 - val_loss: 0.3827 - val_accuracy: 0.8739\n",
      "Epoch 7/20\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3859 - accuracy: 0.8693\n",
      "Images/sec: 1404.09\n",
      "Cumulative training time after epoch 7: 325.11\n",
      "118/118 [==============================] - 43s 362ms/step - loss: 0.3859 - accuracy: 0.8692 - val_loss: 0.3704 - val_accuracy: 0.8776\n",
      "Early stopping after epoch 7\n",
      "Cumulative training time: 325.14\n",
      "Test loss: 0.3724208980798721\n",
      "Test accuracy: 0.8776\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 1 python fashion_mnist.py --epochs 20 --batch-size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 1/29 [>.............................] - ETA: 12:12 - loss: 5.1085 - accuracy: 0.0879WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.849463). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.849449). Check your callbacks.\n",
      " 2/29 [=>............................] - ETA: 5:57 - loss: 4.4244 - accuracy: 0.0898 WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.849487). Check your callbacks.\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.849502). Check your callbacks.\n",
      "28/29 [===========================>..] - ETA: 1s - loss: 1.8466 - accuracy: 0.4609\n",
      "Images/sec: 1594.34\n",
      "Cumulative training time after epoch 1: 37.64\n",
      "29/29 [==============================] - 38s 1s/step - loss: 1.8146 - accuracy: 0.4685 - val_loss: 1.6610 - val_accuracy: 0.4398\n",
      "Epoch 2/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8032 - accuracy: 0.7336\n",
      "Images/sec: 5722.18\n",
      "Cumulative training time after epoch 2: 48.17\n",
      "29/29 [==============================] - 11s 367ms/step - loss: 0.7998 - accuracy: 0.7345 - val_loss: 0.7039 - val_accuracy: 0.7576\n",
      "Epoch 3/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6469 - accuracy: 0.7761\n",
      "Images/sec: 5102.01\n",
      "Cumulative training time after epoch 3: 60.08\n",
      "29/29 [==============================] - 12s 407ms/step - loss: 0.6442 - accuracy: 0.7820 - val_loss: 0.6796 - val_accuracy: 0.7563\n",
      "Epoch 4/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5462 - accuracy: 0.8139\n",
      "Images/sec: 5492.39\n",
      "Cumulative training time after epoch 4: 71.05\n",
      "29/29 [==============================] - 11s 380ms/step - loss: 0.5453 - accuracy: 0.8125 - val_loss: 0.8062 - val_accuracy: 0.7333\n",
      "Epoch 5/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5042 - accuracy: 0.8284\n",
      "Epoch 5: finished gradual learning rate warmup to 0.04.\n",
      "\n",
      "Images/sec: 5282.69\n",
      "Cumulative training time after epoch 5: 82.5\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 0.5031 - accuracy: 0.8307 - val_loss: 1.8091 - val_accuracy: 0.5441\n",
      "Epoch 6/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0224 - accuracy: 0.6895\n",
      "Images/sec: 5634.26\n",
      "Cumulative training time after epoch 6: 93.32\n",
      "29/29 [==============================] - 11s 368ms/step - loss: 1.0144 - accuracy: 0.6922 - val_loss: 0.8059 - val_accuracy: 0.7269\n",
      "Epoch 7/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6222 - accuracy: 0.7863\n",
      "Images/sec: 5630.12\n",
      "Cumulative training time after epoch 7: 104.01\n",
      "29/29 [==============================] - 11s 370ms/step - loss: 0.6206 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.8275\n",
      "Epoch 8/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5357 - accuracy: 0.8177\n",
      "Images/sec: 5701.54\n",
      "Cumulative training time after epoch 8: 114.62\n",
      "29/29 [==============================] - 11s 370ms/step - loss: 0.5352 - accuracy: 0.8175 - val_loss: 0.4746 - val_accuracy: 0.8354\n",
      "Epoch 9/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5092 - accuracy: 0.8256\n",
      "Images/sec: 5283.42\n",
      "Cumulative training time after epoch 9: 126.19\n",
      "29/29 [==============================] - 11s 394ms/step - loss: 0.5110 - accuracy: 0.8258 - val_loss: 0.4529 - val_accuracy: 0.8454\n",
      "Epoch 10/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4846 - accuracy: 0.8368\n",
      "Images/sec: 5626.82\n",
      "Cumulative training time after epoch 10: 136.92\n",
      "29/29 [==============================] - 11s 368ms/step - loss: 0.4846 - accuracy: 0.8354 - val_loss: 0.4384 - val_accuracy: 0.8516\n",
      "Epoch 11/20\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4716 - accuracy: 0.8404\n",
      "Images/sec: 5649.98\n",
      "Cumulative training time after epoch 11: 147.56\n",
      "Early stopping after epoch 11\n",
      "Early stopping after epoch 11\n",
      "Early stopping after epoch 11\n",
      "29/29 [==============================] - 11s 368ms/step - loss: 0.4729 - accuracy: 0.8397 - val_loss: 0.4295 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "Traceback (most recent call last):\n",
      "  File \"fashion_mnist.py\", line 271, in <module>\n",
      "    validation_steps=3 * len(test_iter) // hvd.size())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 1297, in fit_generator\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 1018, in train_on_batch\n",
      "    outputs = self.train_function(ins)  # pylint: disable=not-callable\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.UnknownError:  Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\n",
      "\t [[node training/NovoGrad_Allreduce/HorovodAllreduce_training_NovoGrad_gradients_gradients_AddN_23_0 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_16223]\n",
      "\n",
      "Function call stack:\n",
      "keras_scratch_graph\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Primary job  terminated normally, but 1 process returned\n",
      "a non-zero exit code. Per user-direction, the job has been aborted.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "mpirun detected that one or more processes exited with non-zero status, thus causing\n",
      "the job to be terminated. The first process to do so was:\n",
      "\n",
      "  Process name: [[21628,1],0]\n",
      "  Exit code:    1\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np $num_gpus python fashion_mnist.py --epochs 20 --batch-size 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're fully prepared to take your own training model and distribute it across many GPUs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
